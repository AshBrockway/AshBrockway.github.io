<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Display Webcam Stream</title>

<style>
#container {
	margin: 0px auto;
	width: 640px;
	height: 480px;
	border: 10px #333 solid;
}
#videoElement {
	width: 640px;
	height: 480px;
	background-color: #666;
}
</style>
</head>

<body>
	<!-- loads opencv and the utils -->
	<!-- Tried with opencv 3.4.0 -->
	<script	async	src="js/opencv.js" onload="openCvReady();"
		type="text/javascript"></script>
	<script src="js/utils.js" type="text/javascript"></script>
<!-- Raw input video -->
<p>This is the original video element</p>
<div id="container" class="video">
	<video autoplay="true" id="videoInput" width="640" height="480"></video>
</div>
<!-- Element that shows if openCV has loaded -->
<p id="status">OpenCV.js is loading...</p>
<p id="status_next"></p>
<!-- Output video location. Currently broken -->
<div id = "container">
		<canvas id="canvasOutput" width="640" height="480"></canvas>
</div>


<!-- Converting to grayscale, and placing bounding boxes on video feed. Writes out to bottom canvas -->
<script type="text/javascript"> //For the async loading
function openCvReady() {
  cv['onRuntimeInitialized']=()=>{
    let video = document.getElementById("videoInput"); // video is the id of video tag
	document.getElementById("status").innerHTML = "OpenCV.js has loaded.";
	document.getElementById("status_next").innerHTML = "This is the processed output.";
    navigator.mediaDevices.getUserMedia({ video: true, audio: false })
    .then(function(stream) {
        video.srcObject = stream;
        video.play();
    })
    .catch(function(err) {
        console.log("An error occurred! " + err);
    });
    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
    let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);
    let gray = new cv.Mat();
    let cap = new cv.VideoCapture(videoInput);
    let noses = new cv.RectVector();
    let classifier = new cv.CascadeClassifier();
    let utils = new Utils('errorMessage');
    //let noseCascadeFile = 'https://raw.githubusercontent.com/opencv/opencv/2.4/data/haarcascades/haarcascade_mcs_nose.xml'; // path to xml
    //let noseCascadeFile = "haarcascade_frontalface_default.xml"
    let noseCascadeFile = "Nariz.xml";
    utils.createFileFromUrl(noseCascadeFile, noseCascadeFile, () => {
    classifier.load(noseCascadeFile); // in the callback, load the cascade from file
});
    const FPS = 60;
    function processVideo() {
        let begin = Date.now();
        cap.read(src);
        src.copyTo(dst);
        cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
        try{
            classifier.detectMultiScale(gray, noses, 1.2, 9, 0);
            //console.log(noses.size());
        }catch(err){
            console.log(err);
        }
        for (let i = 0; i < noses.size(); ++i) {
            let face = noses.get(i);
            let point1 = new cv.Point(face.x, face.y);
            let point2 = new cv.Point(face.x + face.width, face.y + face.height);
            cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
            let center_width = new cv.Point(face.x + Math.floor(face.width/2), face.y + Math.floor(face.height/2));
            let adjust = new cv.Point(face.x + Math.floor(face.width/2) + 1, face.y + Math.floor(face.height/2) + 1);
            cv.rectangle(dst, center_width, adjust, [0, 255, 0, 255]);
        }
        cv.imshow("canvasOutput", dst);
        // schedule next one.
        let delay = 1000/FPS - (Date.now() - begin);
        setTimeout(processVideo, delay);
}
// schedule first one.
setTimeout(processVideo, 0);
  };
}
</script>
</body>
</html>
