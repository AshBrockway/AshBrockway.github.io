<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Display Webcam Stream</title>

<style>
#container {
	margin: 0px auto;
	width: 640px;
	height: 480px;
	border: 10px #333 solid;
}
#videoInput {
	width: 640px;
	height: 480px;
	background-color: #666;
}
#canvasOutput{
	width:640px;
	height: 480px;
	background-color: #666;
}

.tooltip {
  position: relative;
  display: inline-block;
  border-bottom: 1px dotted black;
}

.tooltip .tooltiptext {
  visibility: hidden;
  width: 300px;
  background-color: black;
  color: #fff;
  text-align: center;
  border-radius: 6px;
  padding: 5px 0;
  /* Position the tooltip */
  position: absolute;
  z-index: 1;
  top: 100%;
  left: 80%;
  margin-left: -150px;
}

.tooltip:hover .tooltiptext {
  visibility: visible;
}
</style>
</head>

<body>
	<!-- loads opencv and the utils -->
	<!-- Tried with opencv 3.4.0 -->
	<script	async	src="js/opencv.js" onload="openCvReady();"
		type="text/javascript"></script>
	<script src="js/utils.js" type="text/javascript"></script>
<!-- Raw input video -->
This is your webcam stream that the user will see.
<div id="container" class="video">
	<video autoplay="true" id="videoInput" width="640" height="480"></video>
</div>
<!-- Element that shows if openCV has loaded -->
<p id="status">OpenCV.js is loading...</p>
<p id="status_next"></p>
<p id="estimate_fps">Estimated FPS: 0</p>

<!-- Output video location -->
<input type="button" value="Barebones Mode?" onclick="swapBetween(this)"></input><br>
<div id="modelingParams">
	<input type="number" id="scaleFactor" onchange="valueCheck(this)" value=1.2 defaultValue=1.2 min=1.05 max=5>
		<div class="tooltip"> Scale Factor
			<span class="tooltiptext">
				Parameter specifying how much the image size is reduced at each image scale. <br><br>

				Basically the scale factor is used to create your scale pyramid. More explanation can be found <a href="https://sites.google.com/site/5kk73gpu2012/assignment/viola-jones-face-detection#TOC-Image-Pyramid">here</a>. In short the model has a fixed size defined during training, which is visible in the xml. This means that this size of nose is detected in the image if present. However, by rescaling the input image, you can resize a larger face to a smaller one, making it detectable by the algorithm. <br> <br>

				1.05 is a good possible value for this, which means you use a small step for resizing, i.e. reduce size by 5%, you increase the chance of a matching size with the model for detection is found. This also means that the algorithm works slower since it is more thorough. You may increase it to as much as 1.5 for faster detection, with the risk of missing some faces altogether in the "between" space.			</span>
		</div>
	</input>
	<input type="number" id="minNeighbors" onchange="valueCheck(this)" value=8 defaultValue=8 min=0, max=25>
		<div class="tooltip"> Minimum Neighbors
		<span class="tooltiptext">
			Parameter specifying how many neighbors each candidate rectangle should have to retain it. <br> <br>

			This parameter will affect the quality of the detected faces. Higher value results in less detections but with higher quality (less eyebrows for example). 3~8 is a good value for it.
		</span>
		</div>
	</input>
</div>

<!-- Output video location -->
<div id = "container">
		<canvas id="canvasOutput" width="640" height="480"></canvas>
</div>

<!-- Change Alpha And Beta Values -->
<div id="inputs">
	<div id="model_menu" type ="dropbtn" onchange="valueCheck(this)" defaultValue="cascade.xml">Choose a Model</button>
		<a href="cascade.xml">Model 1</a>
		<a href="idk.xl">Model 2</a>
	<input id="alpha" type="number" onchange="valueCheck(this)" value=0.9 defaultValue=0.9 min=0 max=1>Alpha (difference added)</input>
	<input id="beta" type="number" onchange="valueCheck(this)" value=0.9 defaultValue=0.9 min=0 max=1>Beta (momentum decay rate)</input>
	<input id="FPS" type="number" onchange="valueCheck(this)" value=60 defaultValue=60 min=1 max=100>FPS</input><br>
	<input type="checkbox" id="onlybestguess" onclick="valueCheck(this)">Show only best guess</input><br>
	<input type="checkbox" id="rednose" onclick='valueCheck(this)' checked>Show detected Rubix Cube (red box)</input><br>
	<input type="checkbox" id="greendot" onclick="valueCheck(this)" checked>Show center of Rubix Cube (green)</input><br>
	<input type="checkbox" id="bluedot" onclick='valueCheck(this)' checked>Show momentum adjusted point (blue dot)</input> <br>
</div>
<script>
var videotype = true;
function swapBetween(object){
	const value = (object.value == "Barebones Mode?")
	videotype = !value
	if (value){
		object.value = "Fancy Mode?"
    document.getElementById("inputs").style.display = "none"
	} else {
		object.value = "Barebones Mode?"
    document.getElementById("inputs").style.display="block"
	}
};

var momentum = {x:0, y:0};
// FPS is utilized in how frequently the output canvas is updated (with an upper limit on processing speed of computer)
var FPS = document.getElementById("FPS").value;
// The following tow variables are utilized for momentumAdjustments to a detected point

var alpha = document.getElementById("alpha").value; //default 0.9
var beta = document.getElementById("beta").value;
// These are output canvas display variables
var onlybestguess = false
var rednose = true
var greendot = true
var bluedot = true
//These variables effect the detected objects and processing speed of the model
var scaleFactor = + document.getElementById("scaleFactor").value
var minNeighbors = + document.getElementById("minNeighbors").value
function valueCheck(object){
	if (object.id == "minNeighbors"){
		var value = parseInt(object.value)
	}else{
		var value = +object.value
	}
	if(object.type == "number"){
    let max = +object.max
    let min = +object.min
    if (value > max){
      object.value = max
      window[object.id] = max
    } else if (value < min){
      object.value = min
      window[object.id] = min
    } else {
      window[object.id] = value
      console.log(window[object.id])
    }
  } else if (object.type == "checkbox"){
    console.log(object.checked)
    window[object.id] = object.checked
  }
}
</script>


<script type='text/javascript'>
// Defining some helper functions

// provided a list of points (objects of {x, y}) returns the point closest to the previous point
// alternatively, when no previous point provided, chooses the point of minimumm height
function bestGuess(objects, previous){
  if (objects.length == 1){
    objects[0].detected = true
    return objects[0]
  } else if (objects.length > 1){
    if (previous === undefined){
      //Grabs the minimum height detected nose when no previous nose to base off of
      const minimum_height = Math.min(...objects.map(obj=>obj.y));
      const location = objects.findIndex(obj=> obj.y == minimum_height)
      objects[location].detected = true
      return objects[location]
    } else {
      // gets the nose closest to the previous nose
      const distances = objects.map(obj=>((obj.x - previous.x)**2 + (obj.y - previous.y)**2))
      const min_distance = Math.min(...distances)
      const location = distances.findIndex(obj => obj == min_distance)
			let potential_nose = objects[location]
      if (potential_nose === undefined){
        return potential_nose
      } else {
        objects[location].detected = true
      }
      return potential_nose
    }
  } else {
    // condition no detected noses
    if (previous === undefined){
      // I don't think you should have gotten here. No detected noses and no previous nose.
      return undefined
    } else {
      previous.detected = false
      return previous
    }
  }
}

// Adds a bit of momentum to
// alpha is the scaling factor for how much difference in nose locations to add to the momentum
// beta is the exponential decay factor for our momentum
delta = (cur,prev) => ({x:cur.x-prev.x, y:cur.y-prev.y})
sum = (first, second) => ({x:first.x+second.x, y:first.y+second.y})
multScal = (scalar, point) => ({x:point.x*scalar, y: point.y*scalar})
function momentumAdjustment(previous, current){
  if ((current == undefined) && (previous == undefined)){
    return undefined
  } else if (previous == undefined){
    return current
  } else if (current == undefined){
    momentum = multScal(beta, momentum)
    let out = sum(previous, momentum)
    return out
  } else {
    let diff = delta(current,previous)
		const alpha_little = multScal(alpha, diff)
		//console.log(alpha_little)
		const momentum_little = multScal(beta, momentum)
    momentum = sum(alpha_little, momentum_little)
    let out = sum(current, momentum)
		//console.log(out)
    return out
  }
}
</script>

<!-- Converting to grayscale, and placing bounding boxes on video feed. Writes out to bottom canvas -->
<script type="text/javascript"> //For the async loading
function openCvReady() {
  cv['onRuntimeInitialized']=()=>{
    let video = document.getElementById("videoInput");

	//update text about openCV loading
	document.getElementById("status").style.display = "none"// "OpenCV.js has loaded.";
	document.getElementById("status_next").innerHTML = "This is the processed output.";

	//start the the video element to stream from webcam
    navigator.mediaDevices.getUserMedia({ video: true, audio: false })
    .then(function(stream) {
        video.srcObject = stream;
        video.play();
    })
    .catch(function(err) {
        console.log("An error occurred! " + err);
    });
		// actual content
    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
    let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);
    let gray = new cv.Mat();
    let cap = new cv.VideoCapture(videoInput);
    let noses = new cv.RectVector();
    let classifier = new cv.CascadeClassifier();
    let utils = new Utils('errorMessage');
    let noseCascadeFile = "cascade.xml";
    utils.createFileFromUrl(noseCascadeFile, noseCascadeFile, () => {
    	classifier.load(noseCascadeFile); // in the callback, load the cascade from file
		});
		// some variables for momentum method's implementation.
		var undetected_counter = 0
		var previous ;
		centerOfRectangle = obj => ({x: obj.x + Math.floor(obj.width/2), y: obj.y + Math.floor(obj.height/2)})
		function newProcess(){
			//If no detected point (or we guessed the previous point)
			if (previous == undefined || !previous.detected){
				undetected_counter += 1
				if (undetected_counter > 10){ // after enough time, reset our guesses
					momentum = {x:0, y:0}
					previous = undefined
				}
			} else {
				undetected_counter = 0
			}
			// Reading the image and converting to grayscale, etc
		  let begin = Date.now();
		  cap.read(src);
		  src.copyTo(dst);
		  cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
		  try{
		      classifier.detectMultiScale(gray, noses, scaleFactor, minNeighbors, 0);
		  }catch(err){
		      console.log(err);
		  }
		  // Here we find and draw the momentum adjusted point (utilizing bestGuess, and momentumAdjustment)
		  if(bluedot){
					let nose_list = []
					for(i=0; i<noses.size(); i++){
						let n = noses.get(i)
						let out = {x:n.x, y:n.y, height:n.height, width:n.width}
						let update =  nose_list.push(out)
					}
			    let nose_points = nose_list.map(centerOfRectangle)
			    let one_nose = bestGuess(nose_points, previous)
			    let current = momentumAdjustment(previous, one_nose)
			    previous = current
					if (current === undefined){}else{
				    let momentum_point1 = new cv.Point(current.x, current.y)
				    let momentum_point2 = new cv.Point(current.x+1, current.y+1)
				    cv.rectangle(dst, momentum_point1, momentum_point2, [0, 0, 255, 255]);
					}
		  }
		  // Here we detect all of the noses
		  if(!onlybestguess){
		    for (let i = 0; i < noses.size(); ++i) {
		        let nose = noses.get(i);
		        if(rednose){
		          let point1 = new cv.Point(nose.x, nose.y);
		          let point2 = new cv.Point(nose.x + nose.width, nose.y + nose.height);
		          cv.rectangle(dst, point1, point2, [255, 0, 0, 255]); //around the detected nose
		        }
		        if(greendot){
		          let center_width = new cv.Point(nose.x + Math.floor(nose.width/2), nose.y + Math.floor(nose.height/2));
		          let adjust = new cv.Point(nose.x + Math.floor(nose.width/2) + 1, nose.y + Math.floor(nose.height/2) + 1);
		          cv.rectangle(dst, center_width, adjust, [0, 255, 0, 255]); // point on the "center" of the nose.
		        }
		    }
		  } else {
		    // we have to find the best guess nose
				let nose_list = []
				for(i=0; i<noses.size(); i++){
					let n = noses.get(i)
					let out = {x:n.x, y:n.y, height:n.height, width:n.width}
					//document.getElementById("output").innerHTML += "detected out: " +JSON.stringify(out) + "<br>" + "center: " + JSON.stringify(centerOfRectangle(out)) + "<br>"
					let update =  nose_list.push(out)
				}
		    let nose_points = nose_list.map(centerOfRectangle)
		    let one_nose = bestGuess(nose_points, previous)
		    let location = nose_points.findIndex(n => n.x == one_nose.x && n.y == one_nose.y)
				if (location == -1 || location == undefined){}else{
					let nose = noses.get(location)
			    if(rednose){
			      let point1 = new cv.Point(nose.x, nose.y);
			      let point2 = new cv.Point(nose.x + nose.width, nose.y + nose.height);
			      cv.rectangle(dst, point1, point2, [255, 0, 0, 255]); //around the detected nose
			    }
			    if(greendot){
			      let center_width = new cv.Point(nose.x + Math.floor(nose.width/2), nose.y + Math.floor(nose.height/2));
			      let adjust = new cv.Point(nose.x + Math.floor(nose.width/2) + 1, nose.y + Math.floor(nose.height/2) + 1);
			      cv.rectangle(dst, center_width, adjust, [0, 255, 0, 255]); // point on the "center" of the nose.
			    }
				}
		  }

		  cv.imshow("canvasOutput", dst);
		  // schedule next one.
			let time_difference = Date.now() - begin
			let delay = 1000/FPS - time_difference;
			//console.log(time_difference)
			document.getElementById("estimate_fps").innerHTML = "Estimated possible FPS: " + (1000/time_difference).toFixed(2)
			if (videotype){
		  	setTimeout(newProcess, delay);
			} else {
				setTimeout(processVideo,delay)
			}
		}

		function processVideo() {
		    let begin = Date.now();
		    cap.read(src);
		    src.copyTo(dst);
		    cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
		    try{
		        classifier.detectMultiScale(gray, noses, scaleFactor, minNeighbors, 0);
		    }catch(err){
		            console.log(err);
		    }
		    for (let i = 0; i < noses.size(); ++i) {
		        let nose = noses.get(i);
		        let point1 = new cv.Point(nose.x, nose.y);
		        let point2 = new cv.Point(nose.x + nose.width, nose.y + nose.height);
		        cv.rectangle(dst, point1, point2, [255, 0, 0, 255]); //around the detected nose
		        let center_width = new cv.Point(nose.x + Math.floor(nose.width/2), nose.y + Math.floor(nose.height/2));
		        let adjust = new cv.Point(nose.x + Math.floor(nose.width/2) + 1, nose.y + Math.floor(nose.height/2) + 1);
		        cv.rectangle(dst, center_width, adjust, [0, 255, 0, 255]); // point on the "center" of the nose.
		    }
		    cv.imshow("canvasOutput", dst);
		    // schedule next one.
				let time_difference = Date.now() - begin
		    let delay = 1000/FPS - time_difference;
				document.getElementById("estimate_fps").innerHTML = "Estimated possible FPS: " + (1000/time_difference).toFixed(2)
				if(!videotype){
					setTimeout(processVideo, delay);
				}else{
					setTimeout(newProcess, delay)
				}
		}
// schedule first one.
	setTimeout(newProcess, 0);
  };
}
</script>
</body>
</html>
